_wandb:
    value:
        cli_version: 0.21.0
        e:
            kpgsd8pf8zlg79wix5k8hd78srcpogmc:
                args:
                    - --dataset
                    - amazon
                    - --epochs
                    - "3"
                cpu_count: 32
                cpu_count_logical: 64
                cudaVersion: "12.8"
                disk:
                    /:
                        total: "1878767386624"
                        used: "202596642816"
                email: aycacelikaccs@gmail.com
                executable: /work/dlclarge2/celikh-nr1-ayca/miniconda3/envs/automl/bin/python
                git:
                    commit: f52d615cbd2e8e4626050f20f2ea672480c50f32
                    remote: https://github.com/haycacelik/AutoML-Final_Project.git
                gpu: NVIDIA GeForce RTX 2080 Ti
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Turing
                      cudaCores: 4352
                      memoryTotal: "11811160064"
                      name: NVIDIA GeForce RTX 2080 Ti
                      uuid: GPU-34592424-b6d1-d198-4192-4f3ac9a0efdd
                host: dlcgpu02
                memory:
                    total: "540673679360"
                os: Linux-6.8.0-64-generic-x86_64-with-glibc2.35
                program: -m run
                python: CPython 3.10.18
                root: /work/dlclarge2/celikh-nr1-ayca/AutoML-Final_Project
                slurm:
                    cluster_name: kislurm3
                    conf: /var/spool/slurm/conf-cache/slurm.conf
                    cpu_bind: verbose,mask_cpu:0x0000000F0000000F
                    cpu_bind_list: "0x0000000F0000000F"
                    cpu_bind_type: 'mask_cpu:'
                    cpu_bind_verbose: verbose
                    cpus_on_node: "8"
                    gpus_on_node: "1"
                    gpus_per_node: "1"
                    gtids: "0"
                    job_account: lecture
                    job_cpus_per_node: "8"
                    job_end_time: "1753207913"
                    job_gid: "1026"
                    job_group: student
                    job_id: "20147631"
                    job_name: bash
                    job_nodelist: dlcgpu02
                    job_num_nodes: "1"
                    job_partition: dllabdlc_gpu-rtx2080
                    job_qos: normal
                    job_start_time: "1753193513"
                    job_uid: "20698"
                    job_user: celikh
                    jobid: "20147631"
                    launch_node_ipaddr: 10.5.166.214
                    localid: "0"
                    nnodes: "1"
                    nodeid: "0"
                    nodelist: dlcgpu02
                    nprocs: "1"
                    ntasks: "1"
                    prio_process: "0"
                    procid: "0"
                    pty_port: "35783"
                    pty_win_col: "133"
                    pty_win_row: "12"
                    script_context: prolog_task
                    srun_comm_host: 10.5.166.214
                    srun_comm_port: "38801"
                    step_gpus: "0"
                    step_id: "0"
                    step_launcher_port: "38801"
                    step_nodelist: dlcgpu02
                    step_num_nodes: "1"
                    step_num_tasks: "1"
                    step_tasks_per_node: "1"
                    stepid: "0"
                    submit_dir: /work/dlclarge2/celikh-nr1-ayca
                    submit_host: kis3bat1
                    task_pid: "1152538"
                    tasks_per_node: "1"
                    topology_addr: switch-rz.switch-ms2,switch-ms2-r3s9-uplink.switch-ms2-r3s9.dlcgpu02
                    topology_addr_pattern: switch.switch.switch.node
                    umask: "0022"
                startedAt: "2025-07-22T15:45:44.647142Z"
                writerId: kpgsd8pf8zlg79wix5k8hd78srcpogmc
        m: []
        python_version: 3.10.18
        t:
            "1":
                - 1
                - 5
                - 11
                - 49
                - 53
            "2":
                - 1
                - 5
                - 11
                - 49
                - 53
            "3":
                - 16
            "4": 3.10.18
            "5": 0.21.0
            "6": 4.53.3
            "12": 0.21.0
            "13": linux-x86_64
batch_size:
    value: 32
data_fraction:
    value: 1
dataset:
    value: amazon
epochs:
    value: 3
fraction_layers_to_finetune:
    value: 1
lr:
    value: 0.01
seed:
    value: 42
token_length:
    value: 128
val_size:
    value: 0.2
vocab_size:
    value: 1000
weight_decay:
    value: 0.01
